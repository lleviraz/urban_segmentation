<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=fpjTOVmNbO4Lz34iLyptLUXza5VhXqVC6o75Eld_V98');ol.lst-kix_vl2y3gr89f8o-2.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-2 0}.lst-kix_list_2-1>li{counter-increment:lst-ctn-kix_list_2-1}.lst-kix_tugmmxqqti7t-7>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-7,lower-latin) ". "}.lst-kix_tugmmxqqti7t-8>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-8,lower-roman) ". "}.lst-kix_tugmmxqqti7t-5>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-5,lower-roman) ". "}ol.lst-kix_9u7b9wff0k1m-7.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-7 0}ol.lst-kix_knlipr8o3k2w-4.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-4 0}ol.lst-kix_4cfdiapomus2-8{list-style-type:none}ol.lst-kix_4cfdiapomus2-7{list-style-type:none}.lst-kix_tugmmxqqti7t-3>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-3,decimal) ". "}ol.lst-kix_4cfdiapomus2-6{list-style-type:none}ol.lst-kix_4cfdiapomus2-5{list-style-type:none}.lst-kix_tugmmxqqti7t-2>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-2,lower-roman) ". "}.lst-kix_tugmmxqqti7t-6>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-6,decimal) ". "}ol.lst-kix_list_2-3.start{counter-reset:lst-ctn-kix_list_2-3 0}ol.lst-kix_4cfdiapomus2-4{list-style-type:none}ol.lst-kix_4cfdiapomus2-2{list-style-type:none}ol.lst-kix_4cfdiapomus2-1{list-style-type:none}ol.lst-kix_4cfdiapomus2-0{list-style-type:none}.lst-kix_tugmmxqqti7t-4>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-4,lower-latin) ". "}.lst-kix_tugmmxqqti7t-1>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-1,lower-latin) ". "}ol.lst-kix_tks9zkt9j44j-2.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-2 0}.lst-kix_9u7b9wff0k1m-4>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-4}.lst-kix_tugmmxqqti7t-0>li:before{content:"" counter(lst-ctn-kix_tugmmxqqti7t-0,decimal) ". "}.lst-kix_tugmmxqqti7t-0>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-0}ol.lst-kix_list_3-7.start{counter-reset:lst-ctn-kix_list_3-7 0}ol.lst-kix_6pux7l1scn4-0.start{counter-reset:lst-ctn-kix_6pux7l1scn4-0 0}.lst-kix_list_3-2>li{counter-increment:lst-ctn-kix_list_3-2}ol.lst-kix_4cfdiapomus2-1.start{counter-reset:lst-ctn-kix_4cfdiapomus2-1 0}.lst-kix_list_1-4>li{counter-increment:lst-ctn-kix_list_1-4}ol.lst-kix_list_1-6.start{counter-reset:lst-ctn-kix_list_1-6 0}ol.lst-kix_9u7b9wff0k1m-2.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-2 0}.lst-kix_tugmmxqqti7t-4>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-4}.lst-kix_9u7b9wff0k1m-0>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-0}.lst-kix_4cfdiapomus2-6>li{counter-increment:lst-ctn-kix_4cfdiapomus2-6}.lst-kix_list_3-6>li{counter-increment:lst-ctn-kix_list_3-6}ol.lst-kix_tks9zkt9j44j-7.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-7 0}.lst-kix_list_2-5>li{counter-increment:lst-ctn-kix_list_2-5}.lst-kix_list_2-8>li{counter-increment:lst-ctn-kix_list_2-8}ol.lst-kix_list_3-2.start{counter-reset:lst-ctn-kix_list_3-2 0}.lst-kix_tugmmxqqti7t-7>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-7}.lst-kix_tks9zkt9j44j-6>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-6}.lst-kix_knlipr8o3k2w-7>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-7}ol.lst-kix_4cfdiapomus2-6.start{counter-reset:lst-ctn-kix_4cfdiapomus2-6 0}.lst-kix_6pux7l1scn4-8>li{counter-increment:lst-ctn-kix_6pux7l1scn4-8}.lst-kix_6pux7l1scn4-1>li{counter-increment:lst-ctn-kix_6pux7l1scn4-1}.lst-kix_vl2y3gr89f8o-6>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-6,decimal) ". "}.lst-kix_vl2y3gr89f8o-2>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-2,lower-roman) ". "}.lst-kix_tks9zkt9j44j-3>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-3,decimal) ". "}.lst-kix_tks9zkt9j44j-7>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-7,lower-latin) ". "}.lst-kix_vl2y3gr89f8o-8>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-8,lower-roman) ". "}.lst-kix_vl2y3gr89f8o-0>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-0,decimal) ". "}.lst-kix_tks9zkt9j44j-5>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-5,lower-roman) ". "}ol.lst-kix_tugmmxqqti7t-4.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-4 0}.lst-kix_6pux7l1scn4-0>li{counter-increment:lst-ctn-kix_6pux7l1scn4-0}ol.lst-kix_list_3-0.start{counter-reset:lst-ctn-kix_list_3-0 0}ol.lst-kix_tks9zkt9j44j-0.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-0 0}.lst-kix_vl2y3gr89f8o-4>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-4,lower-latin) ". "}ol.lst-kix_list_2-5.start{counter-reset:lst-ctn-kix_list_2-5 0}.lst-kix_list_4-1>li:before{content:"o  "}.lst-kix_list_4-3>li:before{content:"\0025aa  "}.lst-kix_list_4-5>li:before{content:"\0025aa  "}.lst-kix_knlipr8o3k2w-3>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-3}.lst-kix_list_1-8>li{counter-increment:lst-ctn-kix_list_1-8}ol.lst-kix_list_1-4.start{counter-reset:lst-ctn-kix_list_1-4 0}.lst-kix_list_3-5>li{counter-increment:lst-ctn-kix_list_3-5}.lst-kix_4cfdiapomus2-2>li{counter-increment:lst-ctn-kix_4cfdiapomus2-2}ol.lst-kix_list_1-1.start{counter-reset:lst-ctn-kix_list_1-1 0}.lst-kix_tks9zkt9j44j-2>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-2}ol.lst-kix_tugmmxqqti7t-6.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-6 0}ol.lst-kix_vl2y3gr89f8o-7.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-7 0}.lst-kix_7kk3o6lw60im-4>li:before{content:"\0025cb  "}ol.lst-kix_knlipr8o3k2w-2.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-2 0}.lst-kix_7kk3o6lw60im-6>li:before{content:"\0025cf  "}ol.lst-kix_list_2-8.start{counter-reset:lst-ctn-kix_list_2-8 0}.lst-kix_4cfdiapomus2-7>li{counter-increment:lst-ctn-kix_4cfdiapomus2-7}.lst-kix_7kk3o6lw60im-8>li:before{content:"\0025a0  "}.lst-kix_vl2y3gr89f8o-2>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-2}.lst-kix_list_1-3>li{counter-increment:lst-ctn-kix_list_1-3}ol.lst-kix_9u7b9wff0k1m-5.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-5 0}ol.lst-kix_list_3-1{list-style-type:none}ol.lst-kix_list_3-2{list-style-type:none}ol.lst-kix_list_3-3{list-style-type:none}ol.lst-kix_list_3-4.start{counter-reset:lst-ctn-kix_list_3-4 0}ol.lst-kix_list_3-4{list-style-type:none}.lst-kix_tks9zkt9j44j-5>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-5}.lst-kix_9u7b9wff0k1m-3>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-3}ol.lst-kix_list_3-0{list-style-type:none}.lst-kix_list_1-1>li{counter-increment:lst-ctn-kix_list_1-1}ol.lst-kix_list_2-6.start{counter-reset:lst-ctn-kix_list_2-6 0}.lst-kix_list_3-0>li:before{content:"" counter(lst-ctn-kix_list_3-0,decimal) ". "}.lst-kix_list_3-4>li:before{content:"" counter(lst-ctn-kix_list_3-4,lower-latin) ". "}.lst-kix_list_3-3>li:before{content:"" counter(lst-ctn-kix_list_3-3,decimal) ". "}ol.lst-kix_list_3-5{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-4.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-4 0}ol.lst-kix_list_3-6{list-style-type:none}ol.lst-kix_list_3-7{list-style-type:none}ol.lst-kix_list_3-8{list-style-type:none}.lst-kix_knlipr8o3k2w-0>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-0,decimal) ". "}ul.lst-kix_egxnsnud7y8k-8{list-style-type:none}.lst-kix_list_3-8>li:before{content:"" counter(lst-ctn-kix_list_3-8,lower-roman) ". "}ul.lst-kix_egxnsnud7y8k-7{list-style-type:none}ul.lst-kix_egxnsnud7y8k-6{list-style-type:none}ul.lst-kix_egxnsnud7y8k-5{list-style-type:none}ul.lst-kix_egxnsnud7y8k-4{list-style-type:none}ul.lst-kix_egxnsnud7y8k-3{list-style-type:none}ol.lst-kix_knlipr8o3k2w-1.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-1 0}.lst-kix_knlipr8o3k2w-3>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-3,decimal) ". "}ul.lst-kix_egxnsnud7y8k-2{list-style-type:none}ul.lst-kix_egxnsnud7y8k-1{list-style-type:none}ul.lst-kix_egxnsnud7y8k-0{list-style-type:none}.lst-kix_9u7b9wff0k1m-1>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-1}.lst-kix_list_3-7>li:before{content:"" counter(lst-ctn-kix_list_3-7,lower-latin) ". "}ol.lst-kix_vl2y3gr89f8o-5.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-5 0}.lst-kix_knlipr8o3k2w-8>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-8,lower-roman) ". "}.lst-kix_tks9zkt9j44j-7>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-7}.lst-kix_7kk3o6lw60im-3>li:before{content:"\0025cf  "}.lst-kix_knlipr8o3k2w-7>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-7,lower-latin) ". "}.lst-kix_knlipr8o3k2w-4>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-4,lower-latin) ". "}ol.lst-kix_tugmmxqqti7t-8.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-8 0}.lst-kix_7kk3o6lw60im-0>li:before{content:"\0025cf  "}ol.lst-kix_list_2-2{list-style-type:none}ol.lst-kix_list_2-3{list-style-type:none}ol.lst-kix_list_2-4{list-style-type:none}ol.lst-kix_list_2-5{list-style-type:none}ol.lst-kix_list_2-0{list-style-type:none}ol.lst-kix_list_2-1{list-style-type:none}.lst-kix_list_4-8>li:before{content:"\0025aa  "}.lst-kix_list_4-7>li:before{content:"\0025aa  "}.lst-kix_9u7b9wff0k1m-3>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-3,decimal) ". "}ul.lst-kix_list_4-8{list-style-type:none}ul.lst-kix_list_4-6{list-style-type:none}.lst-kix_9u7b9wff0k1m-4>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-4,lower-latin) ". "}ul.lst-kix_list_4-7{list-style-type:none}ul.lst-kix_list_4-0{list-style-type:none}ul.lst-kix_list_4-1{list-style-type:none}ol.lst-kix_list_3-3.start{counter-reset:lst-ctn-kix_list_3-3 0}.lst-kix_9u7b9wff0k1m-8>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-8,lower-roman) ". "}ol.lst-kix_vl2y3gr89f8o-4.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-4 0}ul.lst-kix_list_4-4{list-style-type:none}ol.lst-kix_list_2-6{list-style-type:none}ul.lst-kix_list_4-5{list-style-type:none}ol.lst-kix_list_2-7{list-style-type:none}ul.lst-kix_list_4-2{list-style-type:none}ol.lst-kix_list_2-8{list-style-type:none}.lst-kix_9u7b9wff0k1m-7>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-7,lower-latin) ". "}ul.lst-kix_list_4-3{list-style-type:none}.lst-kix_4cfdiapomus2-0>li{counter-increment:lst-ctn-kix_4cfdiapomus2-0}.lst-kix_6pux7l1scn4-5>li{counter-increment:lst-ctn-kix_6pux7l1scn4-5}.lst-kix_6pux7l1scn4-2>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-2,lower-roman) ". "}.lst-kix_vl2y3gr89f8o-3>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-3}.lst-kix_6pux7l1scn4-3>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-3,decimal) ". "}.lst-kix_6pux7l1scn4-6>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-6,decimal) ". "}.lst-kix_tks9zkt9j44j-0>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-0,decimal) ". "}.lst-kix_tks9zkt9j44j-3>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-3}.lst-kix_list_2-2>li{counter-increment:lst-ctn-kix_list_2-2}.lst-kix_6pux7l1scn4-7>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-7,lower-latin) ". "}ol.lst-kix_knlipr8o3k2w-0.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-0 0}.lst-kix_tks9zkt9j44j-1>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-1,lower-latin) ". "}.lst-kix_list_3-7>li{counter-increment:lst-ctn-kix_list_3-7}.lst-kix_tks9zkt9j44j-4>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-4,lower-latin) ". "}.lst-kix_vl2y3gr89f8o-5>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-5,lower-roman) ". "}.lst-kix_list_2-4>li:before{content:"" counter(lst-ctn-kix_list_2-4,lower-latin) ". "}.lst-kix_list_2-8>li:before{content:"" counter(lst-ctn-kix_list_2-8,lower-roman) ". "}.lst-kix_vl2y3gr89f8o-5>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-5}.lst-kix_vl2y3gr89f8o-1>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-1,lower-latin) ". "}.lst-kix_4cfdiapomus2-1>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-1,decimal) ". "}.lst-kix_tks9zkt9j44j-8>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-8,lower-roman) ". "}ol.lst-kix_list_3-8.start{counter-reset:lst-ctn-kix_list_3-8 0}.lst-kix_list_4-0>li:before{content:"\0025cf  "}ol.lst-kix_vl2y3gr89f8o-1.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-1 0}.lst-kix_list_4-4>li:before{content:"\0025aa  "}ol.lst-kix_list_2-2.start{counter-reset:lst-ctn-kix_list_2-2 0}.lst-kix_knlipr8o3k2w-0>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-0}.lst-kix_9u7b9wff0k1m-0>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-0,decimal) ". "}.lst-kix_4cfdiapomus2-5>li{counter-increment:lst-ctn-kix_4cfdiapomus2-5}ol.lst-kix_9u7b9wff0k1m-0.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-0 0}ol.lst-kix_vl2y3gr89f8o-0{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-1{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-2{list-style-type:none}.lst-kix_knlipr8o3k2w-5>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-5}ol.lst-kix_vl2y3gr89f8o-3{list-style-type:none}.lst-kix_list_2-4>li{counter-increment:lst-ctn-kix_list_2-4}ol.lst-kix_list_3-6.start{counter-reset:lst-ctn-kix_list_3-6 0}ol.lst-kix_vl2y3gr89f8o-8{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-4{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-5{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-6{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-7{list-style-type:none}.lst-kix_6pux7l1scn4-3>li{counter-increment:lst-ctn-kix_6pux7l1scn4-3}.lst-kix_7kk3o6lw60im-7>li:before{content:"\0025cb  "}.lst-kix_list_1-0>li:before{content:"" counter(lst-ctn-kix_list_1-0,decimal) ". "}ol.lst-kix_list_2-0.start{counter-reset:lst-ctn-kix_list_2-0 0}.lst-kix_list_1-4>li:before{content:"" counter(lst-ctn-kix_list_1-4,lower-latin) ". "}ol.lst-kix_list_3-5.start{counter-reset:lst-ctn-kix_list_3-5 0}.lst-kix_list_1-6>li{counter-increment:lst-ctn-kix_list_1-6}.lst-kix_list_2-0>li:before{content:"" counter(lst-ctn-kix_list_2-0,decimal) ". "}ol.lst-kix_list_2-1.start{counter-reset:lst-ctn-kix_list_2-1 0}ol.lst-kix_vl2y3gr89f8o-0.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-0 0}.lst-kix_list_1-8>li:before{content:"" counter(lst-ctn-kix_list_1-8,lower-roman) ". "}.lst-kix_4cfdiapomus2-5>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-5,lower-roman) ". "}.lst-kix_9u7b9wff0k1m-8>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-8}ol.lst-kix_knlipr8o3k2w-2{list-style-type:none}ol.lst-kix_knlipr8o3k2w-1{list-style-type:none}ol.lst-kix_knlipr8o3k2w-4{list-style-type:none}ol.lst-kix_knlipr8o3k2w-3{list-style-type:none}ol.lst-kix_knlipr8o3k2w-6{list-style-type:none}ol.lst-kix_knlipr8o3k2w-5{list-style-type:none}ol.lst-kix_knlipr8o3k2w-8{list-style-type:none}ol.lst-kix_knlipr8o3k2w-7{list-style-type:none}ol.lst-kix_list_3-1.start{counter-reset:lst-ctn-kix_list_3-1 0}.lst-kix_6pux7l1scn4-6>li{counter-increment:lst-ctn-kix_6pux7l1scn4-6}ol.lst-kix_4cfdiapomus2-7.start{counter-reset:lst-ctn-kix_4cfdiapomus2-7 0}ol.lst-kix_9u7b9wff0k1m-1.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-1 0}ol.lst-kix_list_1-5.start{counter-reset:lst-ctn-kix_list_1-5 0}.lst-kix_tugmmxqqti7t-2>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-2}ol.lst-kix_knlipr8o3k2w-0{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-8.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-8 0}.lst-kix_list_2-3>li{counter-increment:lst-ctn-kix_list_2-3}.lst-kix_tks9zkt9j44j-4>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-4}.lst-kix_list_1-2>li{counter-increment:lst-ctn-kix_list_1-2}.lst-kix_4cfdiapomus2-8>li{counter-increment:lst-ctn-kix_4cfdiapomus2-8}ol.lst-kix_tugmmxqqti7t-5.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-5 0}.lst-kix_egxnsnud7y8k-0>li:before{content:"-  "}.lst-kix_egxnsnud7y8k-1>li:before{content:"-  "}ol.lst-kix_tks9zkt9j44j-1.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-1 0}.lst-kix_egxnsnud7y8k-2>li:before{content:"-  "}.lst-kix_egxnsnud7y8k-3>li:before{content:"-  "}ol.lst-kix_tks9zkt9j44j-8.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-8 0}.lst-kix_9u7b9wff0k1m-6>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-6}.lst-kix_egxnsnud7y8k-8>li:before{content:"-  "}.lst-kix_egxnsnud7y8k-6>li:before{content:"-  "}.lst-kix_egxnsnud7y8k-7>li:before{content:"-  "}.lst-kix_egxnsnud7y8k-4>li:before{content:"-  "}.lst-kix_egxnsnud7y8k-5>li:before{content:"-  "}ol.lst-kix_9u7b9wff0k1m-5{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-6{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-3{list-style-type:none}ol.lst-kix_list_1-0.start{counter-reset:lst-ctn-kix_list_1-0 0}ol.lst-kix_9u7b9wff0k1m-4{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-7{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-8{list-style-type:none}.lst-kix_list_3-0>li{counter-increment:lst-ctn-kix_list_3-0}ol.lst-kix_tks9zkt9j44j-4{list-style-type:none}.lst-kix_vl2y3gr89f8o-0>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-0}ol.lst-kix_tks9zkt9j44j-5{list-style-type:none}.lst-kix_6pux7l1scn4-2>li{counter-increment:lst-ctn-kix_6pux7l1scn4-2}ol.lst-kix_tks9zkt9j44j-6{list-style-type:none}ol.lst-kix_tks9zkt9j44j-7{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-1{list-style-type:none}ol.lst-kix_tks9zkt9j44j-8{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-2{list-style-type:none}li.li-bullet-2:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix_9u7b9wff0k1m-0{list-style-type:none}ol.lst-kix_tks9zkt9j44j-0{list-style-type:none}ol.lst-kix_tks9zkt9j44j-1{list-style-type:none}ol.lst-kix_tks9zkt9j44j-2{list-style-type:none}ol.lst-kix_tks9zkt9j44j-3{list-style-type:none}ol.lst-kix_9u7b9wff0k1m-8.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-8 0}ol.lst-kix_vl2y3gr89f8o-3.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-3 0}.lst-kix_tks9zkt9j44j-0>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-0}ol.lst-kix_list_2-4.start{counter-reset:lst-ctn-kix_list_2-4 0}ol.lst-kix_list_1-3{list-style-type:none}ol.lst-kix_list_1-4{list-style-type:none}.lst-kix_list_2-7>li:before{content:"" counter(lst-ctn-kix_list_2-7,lower-latin) ". "}.lst-kix_list_2-7>li{counter-increment:lst-ctn-kix_list_2-7}ol.lst-kix_list_1-5{list-style-type:none}ol.lst-kix_list_1-6{list-style-type:none}ol.lst-kix_list_1-0{list-style-type:none}.lst-kix_list_2-5>li:before{content:"" counter(lst-ctn-kix_list_2-5,lower-roman) ". "}ol.lst-kix_list_1-1{list-style-type:none}.lst-kix_4cfdiapomus2-4>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-4,lower-latin) ". "}.lst-kix_4cfdiapomus2-8>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-8,lower-roman) ". "}ol.lst-kix_list_1-2{list-style-type:none}.lst-kix_tugmmxqqti7t-6>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-6}.lst-kix_4cfdiapomus2-2>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-2,decimal) ". "}ol.lst-kix_6pux7l1scn4-1.start{counter-reset:lst-ctn-kix_6pux7l1scn4-1 0}.lst-kix_4cfdiapomus2-0>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-0,decimal) ". "}ol.lst-kix_4cfdiapomus2-0.start{counter-reset:lst-ctn-kix_4cfdiapomus2-0 0}ol.lst-kix_list_1-7{list-style-type:none}.lst-kix_knlipr8o3k2w-2>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-2}ol.lst-kix_list_1-8{list-style-type:none}ol.lst-kix_4cfdiapomus2-5.start{counter-reset:lst-ctn-kix_4cfdiapomus2-5 0}ol.lst-kix_9u7b9wff0k1m-3.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-3 0}li.li-bullet-1:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_list_2-6>li{counter-increment:lst-ctn-kix_list_2-6}.lst-kix_tks9zkt9j44j-1>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-1}ol.lst-kix_knlipr8o3k2w-5.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-5 0}.lst-kix_9u7b9wff0k1m-1>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-1,lower-latin) ". "}.lst-kix_vl2y3gr89f8o-7>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-7}.lst-kix_list_3-4>li{counter-increment:lst-ctn-kix_list_3-4}.lst-kix_vl2y3gr89f8o-8>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-8}.lst-kix_4cfdiapomus2-1>li{counter-increment:lst-ctn-kix_4cfdiapomus2-1}ol.lst-kix_list_1-3.start{counter-reset:lst-ctn-kix_list_1-3 0}ol.lst-kix_9u7b9wff0k1m-6.start{counter-reset:lst-ctn-kix_9u7b9wff0k1m-6 0}ol.lst-kix_list_1-2.start{counter-reset:lst-ctn-kix_list_1-2 0}ol.lst-kix_4cfdiapomus2-2.start{counter-reset:lst-ctn-kix_4cfdiapomus2-2 0}.lst-kix_list_1-1>li:before{content:"" counter(lst-ctn-kix_list_1-1,lower-latin) ". "}.lst-kix_tugmmxqqti7t-5>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-5}.lst-kix_tks9zkt9j44j-8>li{counter-increment:lst-ctn-kix_tks9zkt9j44j-8}ol.lst-kix_6pux7l1scn4-4{list-style-type:none}.lst-kix_list_1-3>li:before{content:"" counter(lst-ctn-kix_list_1-3,decimal) ". "}ol.lst-kix_6pux7l1scn4-5{list-style-type:none}ol.lst-kix_tugmmxqqti7t-7.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-7 0}ol.lst-kix_6pux7l1scn4-2{list-style-type:none}ol.lst-kix_6pux7l1scn4-3{list-style-type:none}ol.lst-kix_6pux7l1scn4-0{list-style-type:none}ol.lst-kix_6pux7l1scn4-1{list-style-type:none}.lst-kix_list_1-7>li:before{content:"" counter(lst-ctn-kix_list_1-7,lower-latin) ". "}ol.lst-kix_knlipr8o3k2w-3.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-3 0}ol.lst-kix_list_2-7.start{counter-reset:lst-ctn-kix_list_2-7 0}ul.lst-kix_7kk3o6lw60im-0{list-style-type:none}ul.lst-kix_7kk3o6lw60im-2{list-style-type:none}ol.lst-kix_6pux7l1scn4-8{list-style-type:none}.lst-kix_list_1-5>li:before{content:"" counter(lst-ctn-kix_list_1-5,lower-roman) ". "}ul.lst-kix_7kk3o6lw60im-1{list-style-type:none}ol.lst-kix_vl2y3gr89f8o-6.start{counter-reset:lst-ctn-kix_vl2y3gr89f8o-6 0}ul.lst-kix_7kk3o6lw60im-4{list-style-type:none}ol.lst-kix_6pux7l1scn4-6{list-style-type:none}ul.lst-kix_7kk3o6lw60im-3{list-style-type:none}ol.lst-kix_6pux7l1scn4-7{list-style-type:none}ul.lst-kix_7kk3o6lw60im-6{list-style-type:none}.lst-kix_9u7b9wff0k1m-5>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-5}ul.lst-kix_7kk3o6lw60im-5{list-style-type:none}ul.lst-kix_7kk3o6lw60im-8{list-style-type:none}ul.lst-kix_7kk3o6lw60im-7{list-style-type:none}.lst-kix_list_2-1>li:before{content:"" counter(lst-ctn-kix_list_2-1,lower-latin) ". "}.lst-kix_list_2-3>li:before{content:"" counter(lst-ctn-kix_list_2-3,decimal) ". "}.lst-kix_4cfdiapomus2-6>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-6,decimal) ". "}.lst-kix_knlipr8o3k2w-8>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-8}.lst-kix_list_3-1>li{counter-increment:lst-ctn-kix_list_3-1}ol.lst-kix_knlipr8o3k2w-7.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-7 0}ol.lst-kix_4cfdiapomus2-4.start{counter-reset:lst-ctn-kix_4cfdiapomus2-4 0}.lst-kix_6pux7l1scn4-7>li{counter-increment:lst-ctn-kix_6pux7l1scn4-7}ol.lst-kix_6pux7l1scn4-8.start{counter-reset:lst-ctn-kix_6pux7l1scn4-8 0}.lst-kix_tugmmxqqti7t-1>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-1}.lst-kix_list_3-1>li:before{content:"" counter(lst-ctn-kix_list_3-1,lower-latin) ". "}.lst-kix_list_3-2>li:before{content:"" counter(lst-ctn-kix_list_3-2,lower-roman) ". "}ol.lst-kix_tugmmxqqti7t-0{list-style-type:none}ol.lst-kix_tugmmxqqti7t-1{list-style-type:none}ol.lst-kix_tugmmxqqti7t-2{list-style-type:none}ol.lst-kix_list_1-8.start{counter-reset:lst-ctn-kix_list_1-8 0}.lst-kix_list_3-5>li:before{content:"" counter(lst-ctn-kix_list_3-5,lower-roman) ". "}.lst-kix_6pux7l1scn4-0>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-0,decimal) ". "}.lst-kix_knlipr8o3k2w-2>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-2,lower-roman) ". "}.lst-kix_list_2-0>li{counter-increment:lst-ctn-kix_list_2-0}ol.lst-kix_tugmmxqqti7t-7{list-style-type:none}ol.lst-kix_tugmmxqqti7t-2.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-2 0}ol.lst-kix_tugmmxqqti7t-8{list-style-type:none}.lst-kix_list_3-6>li:before{content:"" counter(lst-ctn-kix_list_3-6,decimal) ". "}ol.lst-kix_tugmmxqqti7t-3{list-style-type:none}.lst-kix_knlipr8o3k2w-6>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-6}ol.lst-kix_tugmmxqqti7t-4{list-style-type:none}ol.lst-kix_tugmmxqqti7t-5{list-style-type:none}.lst-kix_knlipr8o3k2w-1>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-1,lower-latin) ". "}ol.lst-kix_tugmmxqqti7t-6{list-style-type:none}.lst-kix_vl2y3gr89f8o-1>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-1}.lst-kix_knlipr8o3k2w-6>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-6,decimal) ". "}.lst-kix_tugmmxqqti7t-3>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-3}.lst-kix_7kk3o6lw60im-2>li:before{content:"\0025a0  "}.lst-kix_7kk3o6lw60im-1>li:before{content:"\0025cb  "}.lst-kix_knlipr8o3k2w-5>li:before{content:"" counter(lst-ctn-kix_knlipr8o3k2w-5,lower-roman) ". "}ol.lst-kix_6pux7l1scn4-3.start{counter-reset:lst-ctn-kix_6pux7l1scn4-3 0}ul.lst-kix_4cfdiapomus2-3{list-style-type:none}.lst-kix_9u7b9wff0k1m-5>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-5,lower-roman) ". "}.lst-kix_9u7b9wff0k1m-6>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-6,decimal) ". "}.lst-kix_6pux7l1scn4-1>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-1,lower-latin) ". "}.lst-kix_list_3-3>li{counter-increment:lst-ctn-kix_list_3-3}.lst-kix_knlipr8o3k2w-1>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-1}ol.lst-kix_knlipr8o3k2w-6.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-6 0}.lst-kix_vl2y3gr89f8o-6>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-6}.lst-kix_6pux7l1scn4-4>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-4,lower-latin) ". "}ol.lst-kix_tugmmxqqti7t-3.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-3 0}ol.lst-kix_6pux7l1scn4-2.start{counter-reset:lst-ctn-kix_6pux7l1scn4-2 0}.lst-kix_6pux7l1scn4-5>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-5,lower-roman) ". "}.lst-kix_knlipr8o3k2w-4>li{counter-increment:lst-ctn-kix_knlipr8o3k2w-4}.lst-kix_tks9zkt9j44j-2>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-2,lower-roman) ". "}.lst-kix_6pux7l1scn4-8>li:before{content:"" counter(lst-ctn-kix_6pux7l1scn4-8,lower-roman) ". "}.lst-kix_vl2y3gr89f8o-3>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-3,decimal) ". "}.lst-kix_4cfdiapomus2-7>li:before{content:"" counter(lst-ctn-kix_4cfdiapomus2-7,lower-latin) ". "}.lst-kix_list_2-6>li:before{content:"" counter(lst-ctn-kix_list_2-6,decimal) ". "}.lst-kix_tks9zkt9j44j-6>li:before{content:"" counter(lst-ctn-kix_tks9zkt9j44j-6,decimal) ". "}ol.lst-kix_tks9zkt9j44j-6.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-6 0}ol.lst-kix_tugmmxqqti7t-1.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-1 0}.lst-kix_vl2y3gr89f8o-7>li:before{content:"" counter(lst-ctn-kix_vl2y3gr89f8o-7,lower-latin) ". "}.lst-kix_4cfdiapomus2-3>li:before{content:"\0025a0  "}.lst-kix_4cfdiapomus2-4>li{counter-increment:lst-ctn-kix_4cfdiapomus2-4}ol.lst-kix_4cfdiapomus2-8.start{counter-reset:lst-ctn-kix_4cfdiapomus2-8 0}ol.lst-kix_tks9zkt9j44j-3.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-3 0}.lst-kix_list_1-7>li{counter-increment:lst-ctn-kix_list_1-7}ol.lst-kix_6pux7l1scn4-4.start{counter-reset:lst-ctn-kix_6pux7l1scn4-4 0}.lst-kix_tugmmxqqti7t-8>li{counter-increment:lst-ctn-kix_tugmmxqqti7t-8}.lst-kix_9u7b9wff0k1m-7>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-7}ol.lst-kix_knlipr8o3k2w-8.start{counter-reset:lst-ctn-kix_knlipr8o3k2w-8 0}.lst-kix_list_3-8>li{counter-increment:lst-ctn-kix_list_3-8}ol.lst-kix_list_1-7.start{counter-reset:lst-ctn-kix_list_1-7 0}.lst-kix_vl2y3gr89f8o-4>li{counter-increment:lst-ctn-kix_vl2y3gr89f8o-4}.lst-kix_list_1-5>li{counter-increment:lst-ctn-kix_list_1-5}ol.lst-kix_6pux7l1scn4-7.start{counter-reset:lst-ctn-kix_6pux7l1scn4-7 0}.lst-kix_9u7b9wff0k1m-2>li:before{content:"" counter(lst-ctn-kix_9u7b9wff0k1m-2,lower-roman) ". "}.lst-kix_list_4-2>li:before{content:"\0025aa  "}.lst-kix_list_4-6>li:before{content:"\0025aa  "}.lst-kix_6pux7l1scn4-4>li{counter-increment:lst-ctn-kix_6pux7l1scn4-4}.lst-kix_7kk3o6lw60im-5>li:before{content:"\0025a0  "}ol.lst-kix_tks9zkt9j44j-5.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-5 0}ol.lst-kix_6pux7l1scn4-6.start{counter-reset:lst-ctn-kix_6pux7l1scn4-6 0}.lst-kix_list_1-2>li:before{content:"" counter(lst-ctn-kix_list_1-2,lower-roman) ". "}.lst-kix_list_1-0>li{counter-increment:lst-ctn-kix_list_1-0}.lst-kix_list_1-6>li:before{content:"" counter(lst-ctn-kix_list_1-6,decimal) ". "}li.li-bullet-0:before{margin-left:-36pt;white-space:nowrap;display:inline-block;min-width:36pt}.lst-kix_9u7b9wff0k1m-2>li{counter-increment:lst-ctn-kix_9u7b9wff0k1m-2}ol.lst-kix_tks9zkt9j44j-4.start{counter-reset:lst-ctn-kix_tks9zkt9j44j-4 0}.lst-kix_list_2-2>li:before{content:"" counter(lst-ctn-kix_list_2-2,lower-roman) ". "}ol.lst-kix_6pux7l1scn4-5.start{counter-reset:lst-ctn-kix_6pux7l1scn4-5 0}ol.lst-kix_tugmmxqqti7t-0.start{counter-reset:lst-ctn-kix_tugmmxqqti7t-0 0}ol{margin:0;padding:0}table td,table th{padding:0}.c11{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:271.5pt;border-top-color:#000000;border-bottom-style:solid}.c60{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#8eaadb;border-top-width:1pt;border-right-width:1pt;border-left-color:#8eaadb;vertical-align:top;border-right-color:#8eaadb;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:77.2pt;border-top-color:#8eaadb;border-bottom-style:solid}.c56{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:270pt;border-top-color:#000000;border-bottom-style:solid}.c74{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:192pt;border-top-color:#000000;border-bottom-style:solid}.c38{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:279pt;border-top-color:#000000;border-bottom-style:solid}.c0{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#8eaadb;border-top-width:1pt;border-right-width:1pt;border-left-color:#8eaadb;vertical-align:top;border-right-color:#8eaadb;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:291.8pt;border-top-color:#8eaadb;border-bottom-style:solid}.c66{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:173.2pt;border-top-color:#000000;border-bottom-style:solid}.c23{border-right-style:solid;padding:0pt 5.4pt 0pt 5.4pt;border-bottom-color:#8eaadb;border-top-width:1pt;border-right-width:1pt;border-left-color:#8eaadb;vertical-align:top;border-right-color:#8eaadb;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:183.8pt;border-top-color:#8eaadb;border-bottom-style:solid}.c13{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c45{background-color:#ffffff;color:#222222;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c25{background-color:#ffffff;padding-top:14pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c21{color:#00b050;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c7{background-color:#fffffe;padding-top:0pt;padding-bottom:0pt;line-height:1.3571428571428572;orphans:2;widows:2;text-align:left}.c18{background-color:#ffffff;padding-top:6pt;padding-bottom:5pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c27{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c53{padding-top:0pt;padding-left:18pt;padding-bottom:0pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c22{color:#1e4d78;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Calibri";font-style:normal}.c49{-webkit-text-decoration-skip:none;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c15{padding-top:2pt;padding-bottom:0pt;line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:12pt}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c65{padding-top:12pt;padding-bottom:12pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c77{padding-top:0pt;padding-bottom:14pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c59{padding-top:0pt;padding-bottom:10pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c26{color:#000000;text-decoration:none;vertical-align:baseline;font-size:18pt;font-family:"Times New Roman";font-style:normal}.c70{padding-top:0pt;padding-bottom:12pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c72{-webkit-text-decoration-skip:none;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:14pt;font-style:normal}.c33{color:#000000;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c73{padding-top:0pt;padding-bottom:8pt;line-height:1.0791666666666666;orphans:2;widows:2;text-align:left}.c17{color:#000000;text-decoration:none;vertical-align:baseline;font-size:24pt;font-family:"Times New Roman";font-style:normal}.c37{color:#2e75b5;text-decoration:none;vertical-align:baseline;font-size:13pt;font-style:normal}.c3{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#0000ff;text-decoration:underline}.c47{margin-left:-5.4pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c16{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c24{margin-left:auto;border-spacing:0;border-collapse:collapse;margin-right:auto}.c61{border-spacing:0;border-collapse:collapse;margin-right:auto}.c32{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c48{text-decoration:none;vertical-align:baseline;font-style:normal}.c54{text-decoration:none;vertical-align:baseline;font-family:"Times New Roman"}.c14{font-size:10.5pt;font-family:"Courier New";font-weight:400}.c40{background-color:#ffffff;max-width:540pt;padding:36pt 36pt 36pt 36pt}.c19{padding:0;margin:0}.c52{font-size:8pt;font-style:italic}.c55{color:#1e4d78;font-size:12pt}.c34{color:#000000;font-size:18pt}.c10{margin-left:36pt;padding-left:0pt}.c76{margin-left:72pt;padding-left:0pt}.c31{font-family:"Calibri";font-weight:400}.c6{color:inherit;text-decoration:inherit}.c30{font-size:11pt}.c2{height:0pt}.c9{background-color:#fffffe}.c64{background-color:#deebf6}.c67{color:#ff0000}.c29{color:#a31515}.c58{background-color:#ffffff}.c71{color:#4f5671}.c41{color:#000000}.c68{font-size:10pt}.c44{height:24pt}.c20{margin-left:36pt}.c42{margin-left:360pt}.c39{font-size:18pt}.c69{font-size:12pt}.c46{font-weight:400}.c78{margin-left:180pt}.c62{vertical-align:super}.c36{font-size:9pt}.c28{color:#09885a}.c79{background-color:#ffff00}.c75{padding-left:18pt}.c50{font-family:"Calibri"}.c12{font-weight:700}.c35{text-indent:36pt}.c51{color:#008000}.c63{font-family:"Times New Roman"}.c43{height:12pt}.c57{color:#212121}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:12pt;font-family:"Times New Roman"}p{margin:0;color:#000000;font-size:12pt;font-family:"Times New Roman"}h1{padding-top:0pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:0pt;font-family:"Times New Roman";line-height:1.0;orphans:2;widows:2;text-align:left}h2{padding-top:2pt;color:#2e75b5;font-size:13pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:2pt;color:#1e4d78;font-size:12pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:2pt;color:#2e75b5;font-size:12pt;padding-bottom:0pt;font-family:"Calibri";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c40 doc-content"><div><p class="c8"><span class="c12 c26">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c33 c12">Efi Arazi School of Computer Science</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 99.33px; height: 90.30px;"><img alt="" src="images/image30.png" style="width: 99.33px; height: 90.30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c33 c12">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Machine Learning and Data Science M.Sc. Program</span></p><p class="c5"><span class="c4"></span></p><p class="c5"><span class="c4"></span></p><p class="c5"><span class="c4"></span></p></div><p class="c1"><span class="c34">Semantic </span><span class="c39">S</span><span class="c34">egmentation of </span><span class="c39">B</span><span class="c34">uilt-</span><span class="c39">U</span><span class="c34">p </span><span class="c39">A</span><span class="c34">reas in </span><span class="c39">S</span><span class="c34">atellite </span><span class="c39">I</span><span class="c34">magery</span></p><p class="c1"><span class="c26 c46">MLDS Project Report</span></p><p class="c8"><span class="c41 c12">Date:</span><span class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Oct </span><span class="c41">202</span><span class="c4">2</span></p><p class="c8"><span class="c41 c12">Mentors:&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41">Dr. Tomer Fishman, Leiden University.</span></p><p class="c8 c20 c35"><span class="c41">Dr. Yoav Peled, IDC School of Sustainability.</span></p><p class="c8 c20 c35"><span class="c41">Dr. Leon Anavy, IDC MLDS</span></p><p class="c8 c20 c35"><span class="c41">Mr. Alon Oring, IDC MLDS</span></p><p class="c8"><span class="c41 c12">Students: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c41">Eli Terris-Assa, 311341879 , </span><span>&nbsp;</span><span class="c41">Liad Levi-Raz,&nbsp; 027398379</span></p><p class="c70 c43"><span class="c4"></span></p><h1 class="c70" id="h.kv86z85oiv1n"><span class="c17 c12">Introduction</span></h1><h2 class="c15" id="h.k48n574aksbx"><span class="c37 c31">The domain</span></h2><p class="c8"><span>Satellite-based sensors capture imagery in visible light and in other wavelengths such as infrared and radar, which reveals a view of heterogeneous environments, composed of natural, agricultural, and </span><span class="c12">built-up areas</span><span class="c4">. These, in turn, vary between different contexts, including natural ones such as continents, climates, water bodies and biomes, and man-made ones such as economic activities, population densities, architectural styles, and urban planning. </span></p><p class="c8"><span>Global environmental change is caused by expansion of human use of the environment, a complex process involving multiple interlinked factors, causes and effects. In order to better understand these processes, the </span><span class="c12">detection </span><span>and</span><span class="c12">&nbsp;classification</span><span class="c4">&nbsp;of different urban morphologies is needed.</span></p><p class="c5"><span class="c41 c12 c49"></span></p><h2 class="c15" id="h.bi5adrbvlue"><span class="c31 c37">The dataset</span></h2><p class="c8"><span class="c4">Our dataset is a collection of satellite images downloaded from Google Earth and their matching manually classified mask images, for residential and non residential areas.</span></p><p class="c5"><span class="c4"></span></p><ol class="c19 lst-kix_knlipr8o3k2w-0 start" start="1"><li class="c20 c53 li-bullet-0"><span class="c30">700 10 meters resolution satellite images of Europe - 13 bands (channels) &ndash; extracted from Google Earth Engine (GEE)</span><span>&nbsp;(</span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1664099106248590&amp;usg=AOvVaw16s6rOmsh4kStDaudO9AuK">Sentinel 2 surface imagery on Google Earth Engine</a></span><span class="c30 c31">)</span></li><li class="c73 c20 c75 li-bullet-0"><span class="c30">700 </span><span class="c30">Mask of Residential vs Non Residential areas (&ldquo;Blue&rdquo;,&ldquo;Green&rdquo; below) &ndash; per pixel segmentation to Residential (Green), non Residential (Blue), and other areas (transparent) &nbsp;- available from the </span><span class="c16 c30"><a class="c6" href="https://www.google.com/url?q=https://land.copernicus.eu/pan-european/GHSL/european-settlement-map/esm-2015-release-2019?tab%3Dmetadata&amp;sa=D&amp;source=editors&amp;ust=1664099106249022&amp;usg=AOvVaw0vKwDhjmNwj8yIUPTVuX6w">Copernicus website for Europe</a></span><span class="c27">&nbsp;only (Resolution of 10m, size will conform to the input image size).</span></li></ol><a id="t.7883da5b08b0f859ab07a0ee82d2c0540f4c56b2"></a><a id="t.0"></a><table class="c24"><tr class="c2"><td class="c66" colspan="1" rowspan="1"><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 209.76px; height: 182.40px;"><img alt="" src="images/image24.png" style="width: 209.76px; height: 182.40px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 224.35px; height: 182.40px;"><img alt="" src="images/image31.png" style="width: 224.35px; height: 182.40px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c2"><td class="c66" colspan="1" rowspan="1"><p class="c1"><span class="c48 c41 c46 c36 c63">An example of an Input image</span></p></td><td class="c74" colspan="1" rowspan="1"><p class="c1"><span class="c48 c41 c46 c36 c63">A mask of Residential vs Non Residential areas</span></p></td></tr></table><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">The dataset originally has the following 11 bands:</span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 720.00px; height: 52.00px;"><img alt="" src="images/image1.png" style="width: 720.00px; height: 52.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c15" id="h.20l29rk2wb08"><span class="c37 c31">The objective</span></h2><p class="c8"><span>The aim of this project is to carry out </span><span class="c12">Semantic Segmentation</span><span class="c4">&nbsp;on space-borne derived data. The project is expected to provide a ML algorithm that will divide the identified built-up areas into different building classes (Residential and Non-Residential) for the general use of sustainability research and/or others.</span></p><p class="c65"><span class="c4">Given a set of satellite images and corresponding masks for these images, detailing which segments are residential and which are non residential, we trained a model to perform image segmentation and then used this model for inferring the segments of new unseen satellite images, and to calculate the proportion of residential and non residential areas in every image. </span></p><h2 class="c15" id="h.9fkot7ppn7if"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 720.00px; height: 310.97px;"><img alt="" src="images/image7.png" style="width: 720.00px; height: 411.77px; margin-left: 0.00px; margin-top: -100.80px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></h2><h2 class="c15" id="h.al376x532twe"><span class="c37 c31">The methods we used </span></h2><p class="c8"><span>For Image Segmentation use cases, and more specifically for Satellite images segmentation, one of the most popular approaches is to use a neural network which is a flavor of the </span><span class="c3"><a class="c6" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/U-Net&amp;sa=D&amp;source=editors&amp;ust=1664099106250974&amp;usg=AOvVaw1R3FlfSvSHan-DsntpYPBe">U-Net architecture</a></span><span>&nbsp;(originally developed for biomedical image segmentation). The network is based on the fully convolutional neural network, where the name &ldquo;U-NET&rdquo; comes from its U-shaped encoder-decoder network architecture, which originally consisted of 4 encoder blocks and 4 decoder blocks that are connected via a latent space. The encoder halves the spatial dimensions and doubles the number of filters (feature channels) at each encoder block, and the decoder doubles the spatial dimensions and halves the number of feature channels</span></p><p class="c5"><span class="c4"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 379.25px; height: 280.84px;"><img alt="" src="images/image5.png" style="width: 379.25px; height: 280.84px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span>Ref: </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://paperswithcode.com/method/u-net&amp;sa=D&amp;source=editors&amp;ust=1664099106251372&amp;usg=AOvVaw1rev6C-tavTZvfvMD0i8lY">U-net</a></span></p><p class="c5"><span class="c41 c12 c63 c72"></span></p><p class="c8"><span class="c4">In addition we also experimented with the &ldquo;DeepLabV3&rdquo; which is currently considered to be the state of the art for image segmentation, however in our experiments we got slightly better results with UNET.</span></p><p class="c5"><span class="c4"></span></p><h2 class="c15" id="h.ih8am8pybgzr"><span class="c37 c31">Major challenges</span></h2><ol class="c19 lst-kix_6pux7l1scn4-0 start" start="1"><li class="c8 c10 li-bullet-1"><span class="c4">One of the main challenges was to learn how to work with multi-channel GeoTIFF images, instead of the &lsquo;default&rsquo; RGB channels; more details on how we approached it in the next section.</span></li><li class="c8 c10 li-bullet-1"><span class="c4">Class imbalance - usually in satellite images this is the case where the background (uninteresting class) captures most of the image, more details on how we approached it in the next section.</span></li><li class="c8 c10 li-bullet-1"><span class="c30">Masks data is available for Europe only &ndash; training can be done on Europe only, thus it is most likely that we will experience distribution drift and inference performance on areas with different characteristics than Europe will be poor. However, since the end purpose is to infer on a &ldquo;Continent level&rdquo; &ndash; it is possible that the error will be reasonable. Another future direction can be to use </span><span>additional annotated data for methods such as Transfer Learning.</span><span class="c30">&nbsp;</span></li><li class="c8 c10 li-bullet-1"><span class="c27">Masks of residential vs non-residential were created by an algorithm we don&rsquo;t have access to, so the model we will create will basically imitate these results (including the errors&hellip;)</span></li><li class="c8 c10 li-bullet-2"><span class="c30">Data export &ndash; the data export process from Google Earth engine is a very sensitive one, in order to provide an end-2-end pipeline of data export and inference, we learned to work with the GEE for exporting new images.</span></li></ol><p class="c5"><span class="c4"></span></p><h1 class="c70 c58 c44" id="h.hnpbz1wavhkb"><span class="c17 c12"></span></h1><h1 class="c70 c58" id="h.46xl8mvjy61n"><span class="c12 c17">Related work</span></h1><p class="c8"><span class="c4">This project does not follow any particular single anchor paper, however the methods we applied for preprocessing, training and evaluation of the model are inspired by the following papers:</span></p><p class="c5"><span class="c4"></span></p><a id="t.fca6cf87c2410c6ed362a9f074b7b55833462aed"></a><a id="t.1"></a><table class="c61"><tr class="c2"><td class="c38" colspan="1" rowspan="1"><p class="c8"><span class="c4">Paper</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c32"><span class="c4">Mainly used by us for&hellip;</span></p></td></tr><tr class="c2"><td class="c38" colspan="1" rowspan="1"><p class="c8"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.mdpi.com/1471460&amp;sa=D&amp;source=editors&amp;ust=1664099106253258&amp;usg=AOvVaw2aUF69I1vuOrCEloVM5taX">Semantic Segmentation and Edge Detection</a></span><span class="c4">&nbsp;(Ghandorh H. et al 2022)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c32"><span class="c4">Inspiration to try various loss functions for class imbalance when training UNET and selection data augmentations, comparison of Dice scores ranges</span></p></td></tr><tr class="c2"><td class="c38" colspan="1" rowspan="1"><p class="c18"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://arxiv.org/pdf/1708.02002.pdf&amp;sa=D&amp;source=editors&amp;ust=1664099106253842&amp;usg=AOvVaw28r-szDktojKsoDH9Pmtdn">Focal Loss for Dense Object Detection</a></span><span>&nbsp; &nbsp;(Tsung-Yi Lin et al. 2018)</span><span class="c48 c46 c63 c57 c69">&nbsp;</span></p><p class="c18"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://arxiv.org/abs/2102.04525&amp;sa=D&amp;source=editors&amp;ust=1664099106254123&amp;usg=AOvVaw3ZQOALiS4znl72uaJaagHg">Unified Focal loss: Generalizing Dice and cross entropy-based losses to handle class imbalanced medical image segmentation</a></span><span class="c57">&nbsp;(Michael Yeung et al. 2021) </span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c32"><span class="c4">Experimentation with a selection of loss functions that handle class imbalance in satellite imagery</span></p></td></tr><tr class="c2"><td class="c38" colspan="1" rowspan="1"><p class="c18"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.mdpi.com/2072-4292/13/12/2292/htm&amp;sa=D&amp;source=editors&amp;ust=1664099106254725&amp;usg=AOvVaw1TCiBf1Te5_p0-l6mqEJs_">Evaluation of Semantic Segmentation Methods for Land Use with Spectral Imaging Using Sentinel-2 and PNOA Imagery</a></span><span class="c4">&nbsp;(Oscar D. Pedrayes et al. 2021)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c32"><span class="c4">Approach and selection of training and evaluation methods for segmentation tasks, more specifically a comparison of UNET and DeepLabV3 hyperparameters tuning, feature selection and results for Sentinel 2 imagery and selection of </span></p></td></tr><tr class="c2"><td class="c38" colspan="1" rowspan="1"><p class="c32"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.researchgate.net/publication/330994618_Separating_Built-Up_Areas_from_Bare_Land_in_Mediterranean_Cities_Using_Sentinel-2A_Imagery&amp;sa=D&amp;source=editors&amp;ust=1664099106255304&amp;usg=AOvVaw1X6XFQOaqIvxOOPUpw_vSj">Separating Built-Up Areas from Bare Land in Mediterranean Cities Using Sentinel-2A Imagery</a></span></p><p class="c32"><span class="c4">(Paria Ettehadi et al. 2019)</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c32"><span class="c4">Inspired by our mentors and this paper we added 4 additional bands to every image - more details in the Preprocessing section below</span></p></td></tr></table><p class="c5"><span class="c4"></span></p><p class="c5"><span class="c4"></span></p><h1 class="c8" id="h.w9fc8295rc7f"><span class="c17 c12">Major Activities</span></h1><h3 class="c15"><span class="c48 c50 c12 c55">Preprocessing</span></h3><p class="c8"><span>As mentioned before, o</span><span class="c4">ne of the main challenges was to learn how to work with multi-channel GeoTIFF images, instead of the &lsquo;default&rsquo; RGB channels.</span></p><p class="c8"><span>We used the </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://rasterio.readthedocs.io/en/latest/&amp;sa=D&amp;source=editors&amp;ust=1664099106256241&amp;usg=AOvVaw34tgim4GsInjVYsqg0-iW0">Rasterio</a></span><span>&nbsp;</span><span class="c4">python library which gives access to geospatial raster data processing and manipulation.</span></p><p class="c8"><span>The Coordinate Reference Systems (CRS) of the images (11 channels from ESPG-3857) and matching masks (1 channel with 4 classes, from ESPG-3035 from </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://land.copernicus.eu/pan-european/GHSL/european-settlement-map/esm-2015-release-2019?tab%3Dmetadata&amp;sa=D&amp;source=editors&amp;ust=1664099106256520&amp;usg=AOvVaw2MWV79SH17y8OqK57OWkuo">Copernicus</a></span><span>) was not aligned, and we had to perform some </span><span class="c12">reprojection </span><span class="c4">in order to align the mask to the images, while trying preserve the proportions of the classes in the mask.</span></p><p class="c8"><span class="c4">The original four classes in the mask are shown below, however we merged classes 0 or 1 as it was not important to distinguish between them in our task:</span></p><ul class="c19 lst-kix_list_4-0 start"><li class="c10 c25 li-bullet-1"><span class="c12">250 </span><span class="c4">for non-residential</span></li><li class="c8 c10 c58 li-bullet-1"><span class="c12">255 </span><span class="c4">for residential</span></li><li class="c8 c10 c58 li-bullet-2"><span class="c4">1 for all other areas (merged into class 0 in before training)</span></li><li class="c10 c58 c77 li-bullet-1"><span class="c12">0 </span><span class="c4">for no-data</span></li></ul><p class="c1"><span style="overflow: hidden; display: inline-block; margin: -0.00px -0.00px; border: 2.67px solid #d9e2f3; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 469.27px; height: 316.11px;"><img alt="" src="images/image23.png" style="width: 469.27px; height: 316.11px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c48 c41 c68 c46 c63">The image above shows a specific example of a mask before and after the reprojection</span></p><p class="c1"><span class="c48 c41 c68 c46 c63">The images dimensions are approx. 300x300 and the masks 200x200, and in addition the CRS of the mask is different. The preprocessing takes care of both aligning the CRS of the mask to its matching image, and align all the images and masks to be in 300x300 resolution, which explains why the pixel counts is much higher for every class</span></p><p class="c8"><span class="c4">&mdash;-------------------------------------------------------------------------------------------------------------------------------</span></p><p class="c8"><span>The following scatter plot, shows the BU area proportion in the </span><span class="c12">original </span><span>vs the </span><span class="c12">preprocessed </span><span class="c4">masks, the closer a red and blue pair is the better &nbsp;- we believe these results are showing that the preprocessing kept the original &nbsp;BU area proportions quite nicely.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 672.29px; height: 238.34px;"><img alt="" src="images/image17.png" style="width: 672.29px; height: 238.34px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><hr style="page-break-before:always;display:none;"><p class="c5"><span class="c4"></span></p><p class="c8"><span>The following plot shows the same information (BU area proportion) in the preprocessed (blue dots) compared to the original (orange diagonal line):</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 533.50px; height: 252.28px;"><img alt="" src="images/image27.png" style="width: 533.50px; height: 252.28px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span>The following histogram shows the same information, the </span><span class="c12">preservation of the proportions</span><span>&nbsp;of the BU area classes before (red) and after (blue) the reprojection of the mask onto the CRS of the matching image &ndash; </span><span class="c12">for the entire dataset. </span><span class="c4">As a reminder the train dataset was extracted based on specific range of class proportions in an image, meaning only images that had a BU Area class proportions (Residential + Non Residential vs others&hellip;) between 17% and 85% were selected - we use this plots to validate the class proportions after preprocessing - we see only very few &lsquo;misses&rsquo;:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 588.50px; height: 232.13px;"><img alt="" src="images/image25.png" style="width: 588.50px; height: 232.13px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 363.50px; height: 144.10px;"><img alt="" src="images/image8.png" style="width: 363.50px; height: 144.10px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c8 c42"><span class="c68">The class proportions on the entire dataset before and after preprocessing, the &lsquo;no-data&rsquo; class became much smaller because of the &lsquo;rotation&rsquo; caused by the CRS alignment.</span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1 c43"><span class="c4"></span></p><h3 class="c15" id="h.lw9j8tjq2z1f"><span class="c22">Additional Features Creation</span></h3><p class="c8"><span>Based on some recommendations and references dealing with similar tasks (</span><span class="c3"><a class="c6" href="https://www.google.com/url?q=https://www.researchgate.net/publication/330994618_Separating_Built-Up_Areas_from_Bare_Land_in_Mediterranean_Cities_Using_Sentinel-2A_Imagery&amp;sa=D&amp;source=editors&amp;ust=1664099106258761&amp;usg=AOvVaw3FRzdZ14qA6ffkTTArxHiy">this paper</a></span><span class="c16 c62"><a class="c6" href="https://www.google.com/url?q=https://www.researchgate.net/publication/330994618_Separating_Built-Up_Areas_from_Bare_Land_in_Mediterranean_Cities_Using_Sentinel-2A_Imagery&amp;sa=D&amp;source=editors&amp;ust=1664099106258994&amp;usg=AOvVaw0SfsggdLy8_Ii7-MZfCyC3">12</a></span><span>), we added</span><span class="c12">&nbsp;4 additional channels</span><span class="c4">&nbsp;to every image(originally exported with 11 bands), which are a combination of the existing channels.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: -0.00px -0.00px; border: 2.67px solid #deebf6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 347.00px; height: 104.49px;"><img alt="" src="images/image26.png" style="width: 347.00px; height: 212.29px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: -0.00px -0.00px; border: 2.67px solid #deebf6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 326.00px; height: 105.70px;"><img alt="" src="images/image26.png" style="width: 326.00px; height: 197.80px; margin-left: -0.00px; margin-top: -92.10px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 722.54px; height: 70.92px;"><img alt="" src="images/image28.png" style="width: 722.54px; height: 70.92px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c48 c41 c68 c46 c63">A plot of the final 15 channels, the first 4 from the right are our addition.</span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">Here are the final 15 bands used in the model training:</span></p><a id="t.46f3d5f09e933269a47a91642d65a721eb5307e7"></a><a id="t.2"></a><table class="c61"><tr class="c2"><td class="c56" colspan="1" rowspan="1"><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">1</span><span class="c14">:</span><span class="c14 c29">&#39;B1_Blue&#39;</span><span class="c14 c41 c48">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">2</span><span class="c14">:</span><span class="c14 c29">&#39;B2_Green&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">3</span><span class="c14">:</span><span class="c14 c29">&#39;B3_Red&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">4</span><span class="c14">:</span><span class="c14 c29">&#39;B4_Red_Edge_1&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">5</span><span class="c14">:</span><span class="c14 c29">&#39;B5_Red_Edge_2&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">6</span><span class="c14">:</span><span class="c14 c29">&#39;B6_Red_Edge_3&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">7</span><span class="c14">:</span><span class="c14 c29">&#39;B7_NIR&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">8</span><span class="c14">:</span><span class="c14 c29">&#39;B8_Red_Edge_4&#39;</span><span class="c14">,</span></p></td><td class="c56" colspan="1" rowspan="1"><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">9</span><span class="c14">:</span><span class="c14 c29">&#39;B9_Water_vapor&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">10</span><span class="c14">:</span><span class="c14 c29">&#39;B10_SWIR_1&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">11</span><span class="c14">:</span><span class="c14 c29">&#39;B11_SWIR_2&#39;</span><span class="c48 c14 c41">,</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">12</span><span class="c14">:</span><span class="c14 c29">&#39;B12_NDVI&#39;</span><span class="c14">, </span><span class="c48 c14 c51">#added by us</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">13</span><span class="c14">:</span><span class="c14 c29">&#39;B13_NDTI&#39;</span><span class="c14">, </span><span class="c48 c14 c51">#added in us</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">14</span><span class="c14">:</span><span class="c14 c29">&#39;B14_NDVIre&#39;</span><span class="c14">, </span><span class="c48 c14 c51">#added by us</span></p><p class="c7"><span class="c14">&nbsp; &nbsp; </span><span class="c14 c28">15</span><span class="c14">:</span><span class="c14 c29">&#39;B15_MNDWI&#39;</span><span class="c14">&nbsp;</span><span class="c14 c51">#added by us</span></p></td></tr></table><p class="c7"><span>A full description of the original 11 bands can be found on the </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR?hl%3Den%23bands&amp;sa=D&amp;source=editors&amp;ust=1664099106262869&amp;usg=AOvVaw2zWGbNvLmWWii1pD1PpXIe">Sentinel 2 page</a></span><span>, as for the 4 additional bands we engineered them based on our mentors suggestion and the following </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.researchgate.net/publication/330994618_Separating_Built-Up_Areas_from_Bare_Land_in_Mediterranean_Cities_Using_Sentinel-2A_Imagery&amp;sa=D&amp;source=editors&amp;ust=1664099106263117&amp;usg=AOvVaw2u_OaSMHBi-irvL7T_nV4C">paper </a></span><span class="c16 c62"><a class="c6" href="https://www.google.com/url?q=https://www.researchgate.net/publication/330994618_Separating_Built-Up_Areas_from_Bare_Land_in_Mediterranean_Cities_Using_Sentinel-2A_Imagery&amp;sa=D&amp;source=editors&amp;ust=1664099106263319&amp;usg=AOvVaw27a88S9GdTxWAap_WAEbud">12</a></span></p><p class="c8"><span class="c4">We experimented with and without the 4 new channels and got small improvements in performance when using them - so they were kept for the final model.</span></p><p class="c5"><span class="c4"></span></p><h3 class="c15"><span class="c48 c55 c50 c12">Selecting metrics and a loss function</span></h3><p class="c8"><span>The major issue in our model training task is the </span><span class="c12">class imbalance</span><span class="c4">, where more than 60% of the pixels are of the &lsquo;1-other&rsquo; class, while we are interested in the proportions of the 250 (for non-residential BU) and 255 (for residential BU) classes (which are usually together only ~30% of the pixels) &ndash; this is typically the case with satellite imagery segmentation tasks, where the background is capturing most of the image (and also with biomedical images) .</span></p><p class="c8"><span>Using a plain </span><span class="c12">&ldquo;accuracy&rdquo; metric</span><span class="c4">&nbsp;in such cases would yield to high accuracy but poor results (the model can naively predict the background class always, and get a high pixel wise accuracy for most images - e.g. we can get 83% accuracy for images with only 17% important classes pixels, by just predicting the &lsquo;background&rsquo; class )</span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">To deal with that we experimented with a few metrics:</span></p><ol class="c19 lst-kix_list_3-0 start" start="1"><li class="c8 c10 li-bullet-1"><span class="c12">IoU (Jaccard Index), Dice Score </span><span>- both measure the overlap of the predicted mask and the original one. Intuitively, a successful prediction is one which maximizes the overlap between the predicted and true objects. &nbsp;The IoU and Dice scores are calculated for </span><span class="c12">each class separately </span><span>and then averaged over all classes to provide </span><span class="c12">a global, mean IoU and Dice scores</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 154.02px; height: 47.00px;"><img alt="" src="images/image3.png" style="width: 421.23px; height: 47.00px; margin-left: -267.21px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 167.05px; height: 47.00px;"><img alt="" src="images/image3.png" style="width: 421.04px; height: 47.00px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ol><p class="c5 c20"><span class="c33 c12"></span></p><p class="c5 c20"><span class="c33 c12"></span></p><ol class="c19 lst-kix_list_3-0" start="2"><li class="c8 c10 li-bullet-1"><span class="c12 c33">Pixel Accuracy (Foreground and overall)</span></li></ol><p class="c8 c20"><span class="c4">Report the percent of correctly classified pixels in the mask, The pixel accuracy is reported for each class separately as well as globally across all classes.(accuracy of the 250 and 250 classes only, ignoring the background classes)</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 206.08px; height: 47.00px;"><img alt="" src="images/image16.png" style="width: 206.08px; height: 47.00px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c20"><span class="c4"></span></p><p class="c8"><span class="c4">Eventually we measured the model performance using the Foreground accuracy and the Dice Score.</span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span>For the same class imbalance issue we experimented with the following </span><span class="c12">loss functions - </span><span class="c4">measuring the per pixel accuracy in the predicted masks vs the original ones:</span></p><ol class="c19 lst-kix_list_1-0 start" start="1"><li class="c8 c10 c9 li-bullet-1"><span class="c12">Cross Entropy Loss (Flat)</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 311.50px; height: 45.17px;"><img alt="" src="images/image15.png" style="width: 311.50px; height: 45.17px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li></ol><p class="c8 c9 c20"><span class="c4">Predicted Mask is a pixel wise probability for each class</span></p><p class="c8 c9 c20"><span class="c4">Each pixel can belong to exactly one target class</span></p><p class="c5 c9"><span class="c4"></span></p><ol class="c19 lst-kix_list_1-0" start="2"><li class="c8 c10 c9 li-bullet-1"><span>Focal Loss</span></li></ol><p class="c8 c9 c20"><span class="c4">Works best with highly-imbalanced dataset, easy-to-classify observations are down-weighted in the loss calculation</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 314.00px; height: 41.21px;"><img alt="" src="images/image20.png" style="width: 314.00px; height: 41.21px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c9"><span class="c4"></span></p><ol class="c19 lst-kix_list_1-0" start="3"><li class="c8 c10 c9 li-bullet-2"><span>Dice Loss</span></li></ol><p class="c8 c9 c20"><span class="c4">Inspired by the Dice Coefficient, a metric to evaluate the overlapping areas &nbsp;(good at FG vs BG but less in &lsquo;easy-to-classify&rsquo; vs hard)</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 250.11px; height: 47.00px;"><img alt="" src="images/image19.png" style="width: 250.11px; height: 47.00px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c9"><span class="c4"></span></p><p class="c5 c9 c20"><span class="c4"></span></p><ol class="c19 lst-kix_list_1-0" start="4"><li class="c8 c10 c9 li-bullet-2"><span>Combined Dice Focal</span></li></ol><p class="c8 c9 c20"><span class="c4">Combined Focal and Dice Loss, to balance between global (Dice) and local (Focal) features on the target mask</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 1.00px solid #e7e6e6; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 301.00px; height: 38.43px;"><img alt="" src="images/image18.png" style="width: 301.00px; height: 38.43px; margin-left: -0.00px; margin-top: -0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c9"><span class="c4"></span></p><p class="c5 c9"><span class="c4"></span></p><p class="c8 c9"><span>Initially when using the fastai framework, the best results were obtained using a &lsquo;</span><span class="c3"><a class="c6" href="https://www.google.com/url?q=https://docs.fast.ai/losses.html%23DiceLoss&amp;sa=D&amp;source=editors&amp;ust=1664099106265837&amp;usg=AOvVaw3nTL2SCv1oEyfo9dmuwhBH">combined Focal and Dice loss&rsquo;</a></span><span>&nbsp;, which is able to balance between global (Dice) and local (Focal) features on the target mask, but when switching to a more simple Pytorch implementation, the &nbsp;</span><span class="c12">CrossEntropyLossFlat </span><span class="c4">was working better in our training procedure.</span></p><p class="c5"><span class="c4"></span></p><h3 class="c15"><span class="c48 c55 c50 c12">Model Training</span></h3><p class="c8"><span class="c4">MinMax Scaling - we attempted to scale the image pixels values with Standard scaler and other recommended initial values, but eventually the best results were obtained when performing MinMax scaling to [0,1].</span></p><p class="c8"><span class="c4">In addition, for all masks, we merged the background class 1 into class 0 &nbsp;- this was done to simplify the complexity of the network (predict 3 classes instead of 4), and as it was not needed to distinguish between the two background classes 0 and 1, we only needed the proportion of the Residential and non-residential classes.</span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">We split the data to 90%-10% train/test split, and used a clean Pytorch UNET implementation which we modified in two ways:</span></p><ol class="c19 lst-kix_vl2y3gr89f8o-0 start" start="1"><li class="c8 c10 li-bullet-1"><span class="c4">Set the input channels to 15 , to be able to get multi band images as input</span></li><li class="c8 c10 li-bullet-1"><span class="c4">We added dropout (0.15-0.3) to fight overfitting</span></li></ol><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">We used an AdamW optimizer with learning rate of 5e-04 and weight decay of 1e-04, and a small batch size of 6 because of our Google Colab GPU capacity limitations.</span></p><p class="c8"><span class="c4">To load the data efficiently in batches in the training loop, we created our own Pytorch Dataset instance (&ldquo;S2ESMDataset&rdquo;)</span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 720.00px; height: 239.39px;"><img alt="" src="images/image9.png" style="width: 720.00px; height: 257.00px; margin-left: 0.00px; margin-top: -17.61px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c48 c41 c46 c36 c63">A sample of an input image before and after MinMax scaling and the corresponding mask </span></p><p class="c1"><span class="c36">(on the </span><span class="c12 c36">True</span><span class="c48 c41 c46 c36 c63">&nbsp;mask: blue is non-residential, red for residential and green is other)</span></p><p class="c1 c43"><span class="c48 c41 c46 c63 c68"></span></p><p class="c8"><span class="c4">Note: in the initial stages of the project we attempted to use the Fastai framework, which includes a UNET architecture (unet_learner), however with these experiments we were not able to achieve satisfying performance on the test data.</span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">Our first approach was to verify that the model is capable of learning by making sure it can overfit for a small dataset, this was successful, and the model was able to imitate the required masks perfectly.</span></p><p class="c8"><span>Then to generalize the model we used the 90-10 train-test split, and applied gently (p=0.2) various augmentations using </span><span class="c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/albumentations-team/albumentations/&amp;sa=D&amp;source=editors&amp;ust=1664099106267384&amp;usg=AOvVaw0fgmTevEZX88SvvzJNwBIN">albumnations</a></span><span class="c4">&nbsp;library:</span></p><ul class="c19 lst-kix_7kk3o6lw60im-0 start"><li class="c8 c10 li-bullet-1"><span class="c4">Random Sized Crop (min_max_height=(298, 298) + Padding</span></li><li class="c8 c10 li-bullet-1"><span class="c4">Random Rotate 90</span></li></ul><p class="c8"><span class="c4">We had to develop some augmentation enhancements for enabling them to work with our multi bands images (default as usual was working with 3 only e.g.RGB channels)</span></p><p class="c8"><span class="c4">Using the augmentations, especially a very mild &ldquo;2 pixels&rdquo; Random Sized Crop, solved an interesting problem where the model tended to predict the non residential class close to the image borders as seen in the image below (squares with red borders on the left):</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 516.50px; height: 238.16px;"><img alt="" src="images/image29.png" style="width: 516.50px; height: 238.16px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">The image above shows our predictions on the SAITAMA area in Japan, this area is considered as an unseen test data, the model was not trained on it, still we can see quite nice results.</span></p><p class="c8"><span class="c4">Here is a sample output of the loss and dice score during training with evaluation, along with the evaluation classification report and confusion matrix.</span></p><p class="c8"><span class="c4">We were able to get an average of 0.889 Dice on the evaluation data:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 409.50px; height: 162.65px;"><img alt="" src="images/image13.png" style="width: 409.50px; height: 162.65px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 285.00px; height: 166.38px;"><img alt="" src="images/image4.png" style="width: 285.00px; height: 259.00px; margin-left: 0.00px; margin-top: -92.62px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8 c20"><span class="c52 c41 c46 c54">Training and validation loss&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;Training and validation Dice score&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Classification confusion matrix (number of pixels)</span></p><p class="c5 c20"><span class="c54 c52 c41 c46"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 384.83px; height: 192.00px;"><img alt="" src="images/image22.png" style="width: 384.83px; height: 192.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c20"><span class="c54 c52 c41 c46">Dice score results per loss function (maximum and average)</span></p><p class="c1 c43"><span class="c4"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px -0.00px; border: 1.33px solid #d9d9d9; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 223.50px; height: 93.00px;"><img alt="" src="images/image4.png" style="width: 285.00px; height: 260.82px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8 c78"><span class="c52">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Classification report for the 3 classes</span></p><hr style="page-break-before:always;display:none;"><h1 class="c8" id="h.ln9b1vmshwcz"><span class="c17 c12">Results</span></h1><p class="c8"><span>Model evaluation is done in two ways, a Dice score calculation and a visual inspection between the true and predicted masks:</span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 720.00px; height: 340.00px;"><img alt="" src="images/image10.png" style="width: 720.00px; height: 340.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">Here is a plot of the best predicted masks, where the BU area ratio difference on the test set is less than 1%:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.00px; height: 213.86px;"><img alt="" src="images/image14.png" style="width: 576.00px; height: 213.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c4">The orange diagonal line represents the BU area ground truth of the test set, the blue dots are the predictions.</span></p><p class="c8"><span class="c4">Roughly speaking the distance from the line is the error margin of every image, and we can see the high correlation (we used Spearman) between the predictions and the ground truth:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.00px; height: 267.51px;"><img alt="" src="images/image11.png" style="width: 576.00px; height: 267.51px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c43"><span class="c4"></span></p><p class="c8"><span class="c4">Here we calculated the BU Area proportion mean error of our model along with its confidence intervals for the global BU area in the middle (both &nbsp;non-residential (250) plus residential (255) vs. the other pixels), and also for every class separately:</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 305.50px; height: 195.28px;"><img alt="" src="images/image21.png" style="width: 305.50px; height: 195.28px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span class="c4">Here is a comparison of the original (blue) vs predicted (orange) BU area distribution, we can see that the prediction is doing quite a nice job achieving almost the same distributions for the non-residential (250) and residential (255) classes.</span></p><p class="c5"><span class="c4"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 484.00px; height: 188.00px;"><img alt="" src="images/image2.png" style="width: 720.00px; height: 188.00px; margin-left: -236.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c8"><span>Finally, here is a sample prediction on unseen data in</span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Saitama_(city)&amp;sa=D&amp;source=editors&amp;ust=1664099106269747&amp;usg=AOvVaw2RXBq6FQWcx5nmxva_oknD">&nbsp;SAITAMA, Japan</a></span><span class="c4">, the image is generated using the Google Earth Engine APIs, and contains 16 predicted urban segmentation masks.</span></p><p class="c8"><span class="c4">There are 3 layers in it:</span></p><p class="c8"><span class="c4">1, The original map from Google Earth (background)</span></p><p class="c8"><span class="c4">2. The Sentinel2 surface satellite &nbsp;images (grayish)</span></p><p class="c8"><span>3. Our prediction mask, in </span><span class="c51">green(</span><span>residential), </span><span class="c67">red(</span><span class="c4">non-residential)</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.50px; height: 467.51px;"><img alt="" src="images/image12.png" style="width: 624.50px; height: 467.51px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c8 c44" id="h.m64u39igeq54"><span class="c17 c12"></span></h1><h1 class="c59" id="h.twa09jz31ki1"><span class="c17 c12">Summary</span></h1><p class="c8"><span class="c4">We learned a lot from this project, mainly the machine learning aspects , but also about managing such an interactive project with the stakeholders, and evolving requirements.</span></p><p class="c8"><span class="c4">We had monthly meetings with our mentors to present the project&rsquo;s status and collect their feedback.</span></p><p class="c8"><span class="c4">Although at a very early stage of the project, we got some nice results, the research effort that was required to improve and get our final results was not negligible. We had to learn how to work with the multi-bands images, and deep dive into the UNET architecture.</span></p><p class="c8"><span class="c4">A key moment to mention was when we were stuck for sometime with some medium quality results which we got quite easily with fastai, and then after consulting our mentors, we decided to &lsquo;start from scratch&rsquo; and to switch from &ldquo;fastai&rdquo; to plain PyTorch implementation. That, and applying some normalization over the input images - gave us the final results which are reported here.</span></p><p class="c8"><span class="c4">We learned a few important tips along the way:</span></p><p class="c8"><span>- To start with making sure your network can </span><span class="c12">overfit </span><span class="c4">to some small sample data - this basic relatively simple operation is critical for validating that your network is complex enough for the task at hand.</span></p><p class="c8"><span class="c4">- Experiment and apply normalization - don&#39;t rely on the random or defaults without trying other options - in our case the MinMax scaler was the best option.</span></p><p class="c8"><span class="c4">- Apply augmentations mildly and gradually to see their effect.</span></p><p class="c8"><span class="c4">- Apply only ONE CHANGE in every experiment and observe its effect.</span></p><p class="c5"><span class="c4"></span></p><p class="c5"><span class="c4"></span></p><p class="c8"><span class="c4">Our final product is a github repository which supports the following &ldquo;Urban segmentation pipeline&rdquo;.</span></p><p class="c8"><span class="c4">Typically this can be used to export new images, preprocess them and infer their urban segmentation masks.</span></p><p class="c8"><span>A more advanced use case can be to train new models based on new future data - all the prerequisites and running instructions can be found in the repo itself: </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://github.com/lleviraz/urban_segmentation%23how-to-use-this-repo&amp;sa=D&amp;source=editors&amp;ust=1664099106271356&amp;usg=AOvVaw2z7wp_X7jnhJnKn_ajKREH">&ldquo;how to use this repo&rdquo; </a></span></p><p class="c8"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 720.00px; height: 405.33px;"><img alt="" src="images/image6.png" style="width: 720.00px; height: 405.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c15" id="h.5xrtyipkbe9t"><span class="c12">Next Steps and Future directions</span></h2><p class="c5 c35"><span class="c4"></span></p><p class="c8"><span class="c4">The ESM data we were using is from 2019, a periodic retraining of the model with fresh images and masks, if available, will probably help keep the model useful for the long range.</span></p><p class="c8"><span class="c4">A possible future enhancement can be to look at a sequence of images and masks along a period of time, and build a model that can predict the urban segmentation proportion changes over time.</span></p><p class="c5 c35"><span class="c4 c79"></span></p><h2 class="c15"><span class="c37 c50 c12">Code and resources</span></h2><p class="c8"><span>See the Git repo: </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://github.com/lleviraz/urban_segmentation&amp;sa=D&amp;source=editors&amp;ust=1664099106272159&amp;usg=AOvVaw2at-lylKCMrdcBQ0PPbzq6">https://github.com/lleviraz/urban_segmentation</a></span></p><p class="c5"><span class="c4"></span></p><h2 class="c15" id="h.spfcqcgkpinc"><span class="c37 c12 c50">References</span></h2><p class="c8 c35"><span class="c4">Data sources and frameworks</span></p><ol class="c19 lst-kix_tugmmxqqti7t-0 start" start="1"><li class="c8 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR?hl%3Den&amp;sa=D&amp;source=editors&amp;ust=1664099106272646&amp;usg=AOvVaw0pXwthCbqD5AkH6hKANFSa">Sentinel 2 surface imagery on Google Earth Engine</a></span><span class="c4">&nbsp;(source for the satellite images)</span></li><li class="c8 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://land.copernicus.eu/pan-european/GHSL/european-settlement-map/esm-2015-release-2019?tab%3Dmetadata&amp;sa=D&amp;source=editors&amp;ust=1664099106272926&amp;usg=AOvVaw3voPzw2_GOuUDxe_hAWFr0">Copernicus</a></span><span>&nbsp;- ESM data 2019 release (source for the segmentation masks)</span></li><li class="c8 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://paperswithcode.com/method/u-net&amp;sa=D&amp;source=editors&amp;ust=1664099106273199&amp;usg=AOvVaw3ba-HqR96VND7OnhSn4MPs">U-Net Explained | Papers With Code</a></span><span class="c4">&nbsp;</span></li><li class="c18 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://paperswithcode.com/method/deeplabv3&amp;sa=D&amp;source=editors&amp;ust=1664099106273504&amp;usg=AOvVaw34fCAELZws18q1wBxh8Zoe">DeepLabv3 Explained | Papers With Code</a></span><span class="c4">&nbsp;</span></li><li class="c10 c18 li-bullet-2"><span>fastai framework</span><span>- </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.fast.ai/&amp;sa=D&amp;source=editors&amp;ust=1664099106273784&amp;usg=AOvVaw0vRlxXRze951fY6NSmz9zc">https://www.fast.ai/</a></span></li><li class="c18 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://rasterio.readthedocs.io/en/latest/&amp;sa=D&amp;source=editors&amp;ust=1664099106274000&amp;usg=AOvVaw10BSm7N_Kh6Oak9VtZV0ff">Rasterio</a></span><span class="c4">&nbsp;</span></li></ol><p class="c18"><span>Papers</span></p><ol class="c19 lst-kix_tugmmxqqti7t-0" start="7"><li class="c8 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.mdpi.com/1471460&amp;sa=D&amp;source=editors&amp;ust=1664099106274280&amp;usg=AOvVaw2E0-WE0UAkpPrdzQBV1iw8">Semantic Segmentation and Edge Detection</a></span><span>&nbsp;(Ghandorh H. et al 2022)</span></li><li class="c18 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://arxiv.org/pdf/1708.02002.pdf&amp;sa=D&amp;source=editors&amp;ust=1664099106274499&amp;usg=AOvVaw03G2azerzuZyglwig9Uek3">Focal Loss for Dense Object Detection</a></span><span>&nbsp; &nbsp;(Tsung-Yi Lin et al. 2018)</span><span class="c57">&nbsp;</span></li><li class="c18 c10 li-bullet-2"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.mdpi.com/2072-4292/13/12/2292/htm&amp;sa=D&amp;source=editors&amp;ust=1664099106274796&amp;usg=AOvVaw2wfUA4jBRnSxOLWzV3GCBh">Evaluation of Semantic Segmentation Methods for Land Use with Spectral Imaging Using Sentinel-2 and PNOA Imagery</a></span><span>&nbsp;(Oscar D. Pedrayes et al. 2021) - results for comparison</span></li><li class="c18 c10 li-bullet-1"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://arxiv.org/abs/2102.04525&amp;sa=D&amp;source=editors&amp;ust=1664099106275023&amp;usg=AOvVaw0wnZON3RrGP130E9Vf96DL">Unified Focal loss: Generalizing Dice and cross entropy-based losses to handle class imbalanced medical image segmentation</a></span><span class="c57">&nbsp;(Michael Yeung et al. 2021) </span></li><li class="c18 c10 li-bullet-2"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.mdpi.com/2072-4292/11/16/1892/htm&amp;sa=D&amp;source=editors&amp;ust=1664099106275273&amp;usg=AOvVaw0rMEB89ZWQzrV15sgbvz8q">Feature selection of Sentinel2 imagery </a></span><span class="c16">(</span><span class="c71"><a class="c6" href="https://www.google.com/url?q=https://sciprofiles.com/profile/733727&amp;sa=D&amp;source=editors&amp;ust=1664099106275435&amp;usg=AOvVaw1uHmPBWBH5h5OYaUastDQe">Zolo Kiala</a></span><span class="c45">&nbsp;et al. 2019)</span></li><li class="c32 c10 li-bullet-2"><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.researchgate.net/publication/330994618_Separating_Built-Up_Areas_from_Bare_Land_in_Mediterranean_Cities_Using_Sentinel-2A_Imagery&amp;sa=D&amp;source=editors&amp;ust=1664099106275716&amp;usg=AOvVaw2zIlPRtJcLhn0vMWdHJVPA">Separating Built-Up Areas from Bare Land in Mediterranean Cities Using Sentinel-2A Imagery</a></span></li></ol><ol class="c19 lst-kix_tugmmxqqti7t-1 start" start="1"><li class="c32 c76 li-bullet-2"><span>(Paria Ettehadi et al. 2019) - additional bands, feature engineering </span></li></ol><ol class="c19 lst-kix_tugmmxqqti7t-0" start="13"><li class="c18 c10 li-bullet-1"><span class="c57">Loss functions for image segmentation: </span><span class="c16"><a class="c6" href="https://www.google.com/url?q=https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook&amp;sa=D&amp;source=editors&amp;ust=1664099106276061&amp;usg=AOvVaw14mhk9y1Xh1-j_nCsa_PwD">https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook</a></span></li></ol><p class="c5"><span class="c4"></span></p><hr style="page-break-before:always;display:none;"><h1 class="c8 c44" id="h.109veg1rw9c0"><span class="c4"></span></h1><h1 class="c8" id="h.92e11noo8sng"><span class="c17 c12">Appendix</span></h1><h2 class="c15" id="h.nmwb1qlq275b"><span class="c37 c31">Project Timeline</span></h2><a id="t.e33ae44bb6df9acbfbe9c64294adf4d05003ac90"></a><a id="t.3"></a><table class="c47"><tr class="c2"><td class="c60 c64" colspan="1" rowspan="1"><p class="c8"><span class="c33 c12">Date</span></p></td><td class="c23 c64" colspan="1" rowspan="1"><p class="c8"><span class="c33 c12">Tasks Description</span></p></td><td class="c0 c64" colspan="1" rowspan="1"><p class="c8"><span class="c33 c12">Status</span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8"><span class="c21">Dec 2021</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">Project Proposal Approval</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c5"><span class="c4"></span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8" id="h.gjdgxs"><span class="c21">Dec 2021-</span></p><p class="c8" id="h.lsfosdartioh"><span class="c21">Jan 2022&nbsp;</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">- Experiment with various Image Segmentation frameworks.</span></p><p class="c8"><span class="c4">- Experiment with a generic end to end training Pipeline.</span></p><p class="c8"><span class="c4">- Experiment with High Resolution images Processing.</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c4">- End of Jan -Dataset downloaded (700 multi-channel Sentinel2 images and matching BU masks)</span></p><p class="c8"><span>- Initial EDA and experimentation with multi-channel GeoTIFF images (using python library </span><span class="c3"><a class="c6" href="https://www.google.com/url?q=https://rasterio.readthedocs.io/en/latest/index.html&amp;sa=D&amp;source=editors&amp;ust=1664099106279187&amp;usg=AOvVaw02LwJCfLo_XiK6me_WUI-o">Rasterio</a></span><span class="c4">)</span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8"><span class="c21">Jan-Feb </span></p><p class="c8"><span class="c21">2022</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">- Exploratory data analysis</span></p><p class="c8"><span class="c4">- Build a baseline pipeline getting initial model results</span></p><p class="c8"><span class="c4">- Select and Experiment with selected architecture, get initial results</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c4">- EDA and Pre-processing pipeline (notebook)</span></p><p class="c8"><span class="c4">- Initial experiments of model training for architecture selection with both FastAI (PyTorch) and Keras</span></p><p class="c8"><span class="c4">- Additional 4 channels added in preprocessing (total of 15 for training)</span></p><p class="c8"><span class="c4">- Unet Training Pipeline running with nice results (notebook)</span></p><p class="c8"><span class="c4">- Selection of a loss function and metrics</span></p><p class="c8"><span class="c4">- Hyper parameter search</span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8"><span class="c21">Mar-Apr 2022</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">Model evaluation and experiment tuning to improve model results</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c4">- PyTorch UNet and Deeplab training pipelines notebooks (experimenting with different architecture modifications)</span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8"><span class="c21">Apr 2022</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">Progress report submission</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c5"><span class="c4"></span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8"><span>May-Sep 2022</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">Create an operational tool for preprocessing, training and inference</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c4">- Final experiments and reorganizing the code in Git for operational use </span></p><p class="c8"><span class="c4">- Final report and running instructions</span></p></td></tr><tr class="c2"><td class="c60" colspan="1" rowspan="1"><p class="c8"><span class="c4">Oct 2022</span></p></td><td class="c23" colspan="1" rowspan="1"><p class="c8"><span class="c4">Demo + Final report submission</span></p></td><td class="c0" colspan="1" rowspan="1"><p class="c8"><span class="c4">- Final Demo and report submission</span></p></td></tr></table><p class="c5"><span class="c4"></span></p><p class="c43 c73"><span class="c4"></span></p><div><p class="c5"><span class="c4"></span></p></div></body></html>